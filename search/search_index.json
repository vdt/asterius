{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"asterius is a Haskell to WebAssembly compiler. The project is in alpha stage and in active development. Sponsors Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Home"},{"location":"#sponsors","text":"Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Sponsors"},{"location":"ahc-link/","text":"Using ahc-link ahc-link is the frontend program of Asterius. It taks a Haskell Main module and optionally an ES6 \"entry\" module as input, then emits a .wasm WebAssembly binary module and companion JavaScript, which can be run in Node.js or browser environments. The options are described in full details here. Basic input/output options --input-hs ARG The Haskell Main module's file path. This option doesn't have a default and is mandatory; all others are optional. --input-mjs ARG The ES6 \"entry\" module's file path. If not specified, the default entry module initializes an Asterius instance and calls Main.main , and upon normal completion, prints the standard output via console.log . It's possible to override the default behavior by specifying your own entry module. First, you need two imports (the relevant files are auto-generated and don't exist yet): import { module } from \"./xx.wasm.mjs\"; import { newInstance } from \"./xx.lib.mjs\"; Assuming xx.hs is the input Haskell Main module. Now, module is a Promise which resolves to a WebAssembly.Module . It's stateless and supports structured cloning, so it's possible to reuse it by send it to Worker s, store it in IndexedDB, etc. To avoid unnecessary compilation when reusing it, you need the dynamic import() for xx.wasm.mjs instead. newInstance is an async function which takes the WebAssembly.Module and resolves to an Asterius instance. An Asterius instance is a super-set of a WebAssembly.Instance and contains stateful fields to support running Haskell code. You can take a look at the manually written entry modules in asterius/test to get some idea on the capabilities of such an instance. --output-directory ARG Specifies the output directory. Defaults to the same directory of --input-hs . --output-prefix ARG Specifies the prefix of the output files. Defaults to the base filename of --input-hs , so for xx.hs , we generate xx.wasm , xx.lib.mjs , etc. Common options for controlling outputs --ghc-option ARG Specify additional ghc options. The {-# OPTIONS_GHC #-} pragma also works. --browser Indicates the output code is to be run in a browser environment. By default, the output code is intended to be run by Node.js instead. --bundle Instead of copying the runtime .mjs modules to the target directory, generate a self-contained xx.js script, and running xx.js has the same effect as running the entry module. Only works for browser targets. --bundle is supported by Parcel under the hood and performs minification on the bundled JavaScript file. It's likely beneficial since it reduces total size of scripts and doesn't require multiple requests for fetching them. --no-streaming Do not use WebAssembly.compileStreaming / WebAssembly.instantiateStreaming in output code. This option only works with --browser ; when the target is Node.js it's ignored. --sync Use synchronous WebAssembly.Module / WebAssembly.Instance constructors in output code. Additionally, The module value exported by xx.wasm.mjs is no longer a Promise , but the WebAssembly.Module value itself. The newInstance function exported by xx.lib.mjs is no longer async, but returns the Asterius instance synchronously. We don't recommend using --sync for most use cases (even for the Node.js target). It's intended for a special use case: Cloudflare Workers, where any initialization logic must be completed on the first run and can't be put in the event queue. More advanced options for hackers --run Runs the output code using node . Ignored for browser targets. --binaryen Use the binaryen backend for generating .wasm files. If you observe any different behavior of output code when this option is on, it's a bug! --debug Switch on the debug mode. Emits a ton of event logs suitable for piping to grep (or just leave it on the screen in case you'd like some hypnosis) --full-sym-table Contain the full symbol table into xx.lib.mjs . Automatically implied by --debug . Options affecting the linker --export-function ARG Use this when you foreign export javascript anything. Otherwise the dead code elimination performed by the linker will surely exclude that code from the output WebAssembly module if it's not transitively used by Main.main ! --extra-root-symbol ARG Use this to specify a symbol to be added to the \"root symbol set\". Works similar to --export-function , but the argument is not a Haskell function name, but a symbol name directly. Additional outputs for the curious --output-link-report Output a \"link report\" text file containing internal linker stats. --output-graphviz Output a .dot GraphViz file containing a symbol dependency graph file. --output-ir Output wasm IRs of compiled Haskell modules and the resulting module. The IRs aren't intended to be consumed by external tools like binaryen/wabt.","title":"Using ahc-link"},{"location":"ahc-link/#using-ahc-link","text":"ahc-link is the frontend program of Asterius. It taks a Haskell Main module and optionally an ES6 \"entry\" module as input, then emits a .wasm WebAssembly binary module and companion JavaScript, which can be run in Node.js or browser environments. The options are described in full details here.","title":"Using ahc-link"},{"location":"ahc-link/#basic-inputoutput-options","text":"","title":"Basic input/output options"},{"location":"ahc-link/#-input-hs-arg","text":"The Haskell Main module's file path. This option doesn't have a default and is mandatory; all others are optional.","title":"--input-hs ARG"},{"location":"ahc-link/#-input-mjs-arg","text":"The ES6 \"entry\" module's file path. If not specified, the default entry module initializes an Asterius instance and calls Main.main , and upon normal completion, prints the standard output via console.log . It's possible to override the default behavior by specifying your own entry module. First, you need two imports (the relevant files are auto-generated and don't exist yet): import { module } from \"./xx.wasm.mjs\"; import { newInstance } from \"./xx.lib.mjs\"; Assuming xx.hs is the input Haskell Main module. Now, module is a Promise which resolves to a WebAssembly.Module . It's stateless and supports structured cloning, so it's possible to reuse it by send it to Worker s, store it in IndexedDB, etc. To avoid unnecessary compilation when reusing it, you need the dynamic import() for xx.wasm.mjs instead. newInstance is an async function which takes the WebAssembly.Module and resolves to an Asterius instance. An Asterius instance is a super-set of a WebAssembly.Instance and contains stateful fields to support running Haskell code. You can take a look at the manually written entry modules in asterius/test to get some idea on the capabilities of such an instance.","title":"--input-mjs ARG"},{"location":"ahc-link/#-output-directory-arg","text":"Specifies the output directory. Defaults to the same directory of --input-hs .","title":"--output-directory ARG"},{"location":"ahc-link/#-output-prefix-arg","text":"Specifies the prefix of the output files. Defaults to the base filename of --input-hs , so for xx.hs , we generate xx.wasm , xx.lib.mjs , etc.","title":"--output-prefix ARG"},{"location":"ahc-link/#common-options-for-controlling-outputs","text":"","title":"Common options for controlling outputs"},{"location":"ahc-link/#-ghc-option-arg","text":"Specify additional ghc options. The {-# OPTIONS_GHC #-} pragma also works.","title":"--ghc-option ARG"},{"location":"ahc-link/#-browser","text":"Indicates the output code is to be run in a browser environment. By default, the output code is intended to be run by Node.js instead.","title":"--browser"},{"location":"ahc-link/#-bundle","text":"Instead of copying the runtime .mjs modules to the target directory, generate a self-contained xx.js script, and running xx.js has the same effect as running the entry module. Only works for browser targets. --bundle is supported by Parcel under the hood and performs minification on the bundled JavaScript file. It's likely beneficial since it reduces total size of scripts and doesn't require multiple requests for fetching them.","title":"--bundle"},{"location":"ahc-link/#-no-streaming","text":"Do not use WebAssembly.compileStreaming / WebAssembly.instantiateStreaming in output code. This option only works with --browser ; when the target is Node.js it's ignored.","title":"--no-streaming"},{"location":"ahc-link/#-sync","text":"Use synchronous WebAssembly.Module / WebAssembly.Instance constructors in output code. Additionally, The module value exported by xx.wasm.mjs is no longer a Promise , but the WebAssembly.Module value itself. The newInstance function exported by xx.lib.mjs is no longer async, but returns the Asterius instance synchronously. We don't recommend using --sync for most use cases (even for the Node.js target). It's intended for a special use case: Cloudflare Workers, where any initialization logic must be completed on the first run and can't be put in the event queue.","title":"--sync"},{"location":"ahc-link/#more-advanced-options-for-hackers","text":"","title":"More advanced options for hackers"},{"location":"ahc-link/#-run","text":"Runs the output code using node . Ignored for browser targets.","title":"--run"},{"location":"ahc-link/#-binaryen","text":"Use the binaryen backend for generating .wasm files. If you observe any different behavior of output code when this option is on, it's a bug!","title":"--binaryen"},{"location":"ahc-link/#-debug","text":"Switch on the debug mode. Emits a ton of event logs suitable for piping to grep (or just leave it on the screen in case you'd like some hypnosis)","title":"--debug"},{"location":"ahc-link/#-full-sym-table","text":"Contain the full symbol table into xx.lib.mjs . Automatically implied by --debug .","title":"--full-sym-table"},{"location":"ahc-link/#options-affecting-the-linker","text":"","title":"Options affecting the linker"},{"location":"ahc-link/#-export-function-arg","text":"Use this when you foreign export javascript anything. Otherwise the dead code elimination performed by the linker will surely exclude that code from the output WebAssembly module if it's not transitively used by Main.main !","title":"--export-function ARG"},{"location":"ahc-link/#-extra-root-symbol-arg","text":"Use this to specify a symbol to be added to the \"root symbol set\". Works similar to --export-function , but the argument is not a Haskell function name, but a symbol name directly.","title":"--extra-root-symbol ARG"},{"location":"ahc-link/#additional-outputs-for-the-curious","text":"","title":"Additional outputs for the curious"},{"location":"ahc-link/#-output-link-report","text":"Output a \"link report\" text file containing internal linker stats.","title":"--output-link-report"},{"location":"ahc-link/#-output-graphviz","text":"Output a .dot GraphViz file containing a symbol dependency graph file.","title":"--output-graphviz"},{"location":"ahc-link/#-output-ir","text":"Output wasm IRs of compiled Haskell modules and the resulting module. The IRs aren't intended to be consumed by external tools like binaryen/wabt.","title":"--output-ir"},{"location":"architecture/","text":"High-level architecture The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected. About \"booting\" In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"Project architecture"},{"location":"architecture/#high-level-architecture","text":"The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.","title":"High-level architecture"},{"location":"architecture/#about-booting","text":"In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"About \"booting\""},{"location":"building/","text":"Building guide asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience. Using a pre-built Docker image We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ... Building custom ghc asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction). Extra dependencies Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway. Building asterius stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building guide"},{"location":"building/#building-guide","text":"asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience.","title":"Building guide"},{"location":"building/#using-a-pre-built-docker-image","text":"We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ...","title":"Using a pre-built Docker image"},{"location":"building/#building-custom-ghc","text":"asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction).","title":"Building custom ghc"},{"location":"building/#extra-dependencies","text":"Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway.","title":"Extra dependencies"},{"location":"building/#building-asterius","text":"stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building asterius"},{"location":"custom-ghc/","text":"About the custom GHC fork Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"custom-ghc/#about-the-custom-ghc-fork","text":"Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"debugging/","text":"The runtime debugging feature There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!) Virtual address spaces Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning. Complete list of emitted debugging log entries Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here. Dumping IRs There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"The runtime debugging feature"},{"location":"debugging/#the-runtime-debugging-feature","text":"There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)","title":"The runtime debugging feature"},{"location":"debugging/#virtual-address-spaces","text":"Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning.","title":"Virtual address spaces"},{"location":"debugging/#complete-list-of-emitted-debugging-log-entries","text":"Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here.","title":"Complete list of emitted debugging log entries"},{"location":"debugging/#dumping-irs","text":"There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"Dumping IRs"},{"location":"ir/","text":"IR types and transformation passes This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI) Cmm IR Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first. Pre-linking expression IR We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units. The store There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store. Post-linking expression IR At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging. Generating binary code via binaryen Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work. Generating binary code via wasm-toolkit We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen . Generating JavaScript stub script To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"IR types and transformation passes"},{"location":"ir/#ir-types-and-transformation-passes","text":"This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI)","title":"IR types and transformation passes"},{"location":"ir/#cmm-ir","text":"Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first.","title":"Cmm IR"},{"location":"ir/#pre-linking-expression-ir","text":"We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units.","title":"Pre-linking expression IR"},{"location":"ir/#the-store","text":"There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store.","title":"The store"},{"location":"ir/#post-linking-expression-ir","text":"At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging.","title":"Post-linking expression IR"},{"location":"ir/#generating-binary-code-via-binaryen","text":"Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work.","title":"Generating binary code via binaryen"},{"location":"ir/#generating-binary-code-via-wasm-toolkit","text":"We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen .","title":"Generating binary code via wasm-toolkit"},{"location":"ir/#generating-javascript-stub-script","text":"To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"Generating JavaScript stub script"},{"location":"jsffi/","text":"JavaScript FFI There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function. Converting between Haskell and JavaScript types The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass. What's permitted in foreign import javascript In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead. Implementation This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature. Syntactic sugar As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time. TODO Adding a JSFFI basic type Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSREF , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"JavaScript FFI"},{"location":"jsffi/#javascript-ffi","text":"There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function.","title":"JavaScript FFI"},{"location":"jsffi/#converting-between-haskell-and-javascript-types","text":"The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass.","title":"Converting between Haskell and JavaScript types"},{"location":"jsffi/#whats-permitted-in-foreign-import-javascript","text":"In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead.","title":"What's permitted in foreign import javascript"},{"location":"jsffi/#implementation","text":"This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature.","title":"Implementation"},{"location":"jsffi/#syntactic-sugar","text":"As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time.","title":"Syntactic sugar"},{"location":"jsffi/#todo","text":"","title":"TODO"},{"location":"jsffi/#adding-a-jsffi-basic-type","text":"Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSREF , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"Adding a JSFFI basic type"},{"location":"readings/","text":"Reading list Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"readings/#reading-list","text":"Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"reports/","text":"Status reports This page maintains a list of weekly status reports for the project. 2019-02-04 Covers last week. Ongoing work: Finished the preliminary implementation of GC. To increase reliability and catch regressions, after each GC pass, the recycled space is zeroed. If the tospace still contains pointers to recycled space (which is definitely a bug), the program is likely to crash early. This has helped us to identify & fix a few bugs in the GC implementation. Right now there is only one regression left: the todomvc example crashes after initial loading completes. The crash goes away if we don't zero recycled space, but it's not a good idea to just turn that off and pretend there's no bug! Remaining work for GC: Fix the todomvc regression. Given GC is such a critical component in the runtime, it's probably also good timing to integrate some more unit tests from the GHC test suite. This also needs some improvement in our debugging infrastructure: our memory traps (wasm read/write barriers) is currently unaware of recycled/live space, and now we should make it cooperate with the allocator to catch invalid access to recycled space earlier. Known drawbacks of current GC implementation once it's fully fixed & merged: No generational GC yet, so high GC overhead if a large volume of long-lived data is retained through program execution. Heap fragmentation is more severe when allocating a lot of small pinned objects. Weak# support is expected to split into two different stages and will land after initial GC merge: Support for running \"C finalizers\" added by the addCFinalizerToWeak# primop. Here, the \"C finalizers\" are really just JavaScript functions, and the \"function pointers\" are JavaScript references. Support for running arbitrary IO action as finalizers. This task requires support for Haskell multi-threading, and given multi-threading is not a scheduled goal of 2019 Q1, this will come later. Haskell closures exported to JavaScript using makeHaskellCallback* cannot be automatically recycled when they aren't used anymore. This is due to JavaScript's lacking of finalizers; users will need to call freeHaskellCallback* by hand to prevent leaking on the Haskell side. We'll yield to Cabal support & TH/GHCi/Plugins support after the first version of GC is delivered. There's definitely room for improvement later (e.g. reduce heap fragmentation, different GC algorithms for different workloads, more detailed GC statistics, etc), but those will be managed by separate tickets. 2019-01-28 Covers last week. Ongoing work: More work to improve the sanity checker and get GC near completion: The sanity checker spotted a fatal situation where previously unreachable static closures become reachable again. More experiments in this direction invalidated a previous conjecture that no special treatments for static closure is required as long as they have valid block descriptors and can be moved just like dynamic ones. The solution to the problem above is not hard: when scanning an info table, we also follow the SRT if it's present, and we still need to identify static/dynamic closures and prevent moving static ones. This is implemented in the sanity checker. The sanity checker is no longer backed by explicit recursion. When scanning a long chain of closures, we won't run out of JavaScript stack space. Adjusting the codegen & standard libraries to cope with upcoming GC: The makeHaskellCallback* interfaces now properly allocate a stable pointer for the exported Haskell closure. This is to ensure that they remain valid when later called from JavaScript, even after GC runs. The function closures of foreign export javascript clauses are recognized and become GC roots for similar reasons. Asterius.Types is moved from ghc-prim to base , so the JSVal type can be backed by StablePtr . The GC will use a tag bit to identify regular stable pointers and JavaScript references, and automatically free unused references. Integer is promoted to a standalone datatype, so the GC can scan reachable Integer s and free unreachable ones which point to BigInt s. Remaining work for GC: Implement evac/scav functionality. Implement support for Weak# s based on the constraint that no Haskell execution is required when firing a finalizer. 2019-01-21 Covers last week. Ongoing work: Bugfixes & partially done GC work of later stages (recycling Haskell heap space & JavaScript references): Unified treatment of regular StablePtr# s and JSVal in the runtime. They are identified by a tag bit, and GC will be able to recognize live JSVal s when scanning the Haskell heap. Added the SPT as sanity check/garbage collection roots. Fixed a sanity check bug related to AP/PAP heap objects. This could be triggered when checking the SPT after passing a closure built by chained rts_apply calls to rts_evalStableIO . Reimplemented the linker layout code. We now put non-closures & closures to separate regions, and the regions are statically allocated block groups which is handled by the sm uniformly like dynamically allocated groups. This enables us to treat static closures as if they're dynamic ones without any special hack. Simplified the block allocator. We no longer manage block at 4K granularity; now we only manage 1M sized ones. Pros & cons: Much fewer blocks needed to manage, so simpler/faster runtime code. Larger nurseries mean the Haskell mutator code signals HeapOverflow much less frequently. Should reduce amortized GC cost. The main drawback is increated heap fragmentation when it comes to allocating lots of small pinned objects. This is not yet a primary concern, and can be addressed later by a hybrid GC which switches to non-moving mark-sweep algorithm for block groups with pinned objects. Added functionality to free block groups, so they can later be reused without growing the linear memory. Their payloads can be zeroed to eliminate a potential attack surface (or for better reproduction of bugs in case something goes wrong) Moved allocate* to the JavaScript runtime and properly implemented allocatePinned . Previously it was simply an alias of allocate since we didn't move anything around. Planned work for next week: Wrap up all GC work and get a fully functional GC up & running. This was originally planned to finish by end of last week, but fell behind schedule due to the hidden workload described above. Required work: Implement evac/scav functionalities in the runtime. Remove the now obsolete symbol table exporting mechanism, and any closure required to survive all GC scans need to be explicitly present in the SPT upon startup. Remove the terrible hacks of directly coercing between GC pointers of boxed types and regular Addr# s when crossing the FFI boundary. Now we must properly pass StablePtr# s. Breaking refactorings in the current boot libs: The JSVal family of types need to be moved from ghc-prim to base (or a separate package depending on base ), since it needs to be a newtype wrapper of StablePtr which is defined in base . The Integer type gets promoted to a standalone datatype. We still use tagging to identify small Integer s and BigInt s which is managed by SPT just like other JSVal s. 2019-01-13 Covers the last week. The week before was new year vacation; happy new year everyone! Completed & ongoing work: Completed the \"modularized runtime\" refactorings. (#50) Drafted three feature roadmaps: Implement proper garbage collection (#52) Implement Cabal support (#53) Implement support for Template Haskell/GHCi/Plugins (#54) The above proposals are scheduled to be completed on 2019 Q1. Began working on GC, and finished the first stage: accurate heap objects traversal. Identify different types of data sections in object files (regular bytes/info tables/closures). The info table addresses are emitted into generated JavaScript to allow an accurate info table sanity check. Implemented runtime utils for directly manipulating the linear memory with tagged addresses. Implemented the sanity check which traverses the whole heap and visits every live object. All existing unit tests pass this check. Planned work for next week: Finish the second stage of GC support: evacuate/scavenge. See #52 for details. After this is finished, GC will be operational. Support for handling JSVal and Weak# is scheduled in later stages. Originally scheduled but lowered priority: Improving the Cloudflare worker demo. We're prioritizing more pressing issues like GC over specific use cases right now. Special thanks to Moritz Angermann (@angerman) for contributing a patch (#55) for fixing ar problem on macOS, and helping to improve macOS & cabal support, discovering a GHC bug related to tables-next-to-code (#16174). 2018-12-28 Covers the last two weeks. Completed work: Significant refactorings in the runtime. Pruned ~500 loc weed code in Asterius.Builtins without breaking tests. Enhanced the scheduler. Previously, when entering a Haskell thread, we evaluated to completion and checked the return code; if something goes wrong, we would just throw an error. Now, the scheduler is capable of handling certain scenarios like heap overflow and resuming Haskell execution. Enhanced the storage manager. Previously, the block allocator always triggered a grow_memory opcode when requesting blocks, making a lot of Array# / ByteArray# related primops rather in-efficient. Also, we allocated a huge heap (defaults to 1G) upon startup and pretended it won't run out. Now, the block allocator grows the linear memory efficiently. And the initial heap is small (4K for both the nursery and the object pool); an overflow condition automatically extends it. Implemented the \"persistent vault\" feature. Every asterius instance has a KV store called a \"vault\" which can be accessed in both Haskell/JavaScript. It can be used to transfer state across instances, so when an instance throws errors we can't handle, we can restart a new one without losing context. This is a part of the work for Cloudflare Worker showcase. Delivered a working TodoMVC example and issued a blog post. Other notable bugfixes/improvements: Fixed the dirty_MUT_VAR write barrier for MutVar# s. All non-atomic MutVar# / IORef / STRef operations now work. This is a part of the work for TodoMVC showcase. We implemented UTF8/UTF16-LE/UTF32-LE/Latin-1 encoding/decoding in the runtime. This is a part of the work for text support. The makeHaskellCallback functions are slightly more efficient by avoiding the overhead of allocating StablePtr s. On-going work not completed yet: Modularizing the runtime. Previously, the runtime is a single monolithic JavaScript script which is pasted into the output script. We'd like to split it to modules, and allow users to supply their own module to override the default behavior (evaluating Main.main once). Rationales: For users, it's much more convenient to implement custom logic via a proper module file. Especially in the Cloudflare Worker case, where we need: Fully synchronous initialization Capturing errors/rebooting a new instance It's now possible to write tests for individual pieces of the runtime. This is critical to improve the runtime's reliability. There were some pasted parts in the monolithic runtime; now we can properly reuse code. It's also convenient to inject link-time information into the runtime. We've introduced parcel into our toolchain to implement a \"bundling\" functionality: at link-time, re-generating a standalone .js file containing all the runtime modules. This is already implemented. We're gradually splitting the monolithic runtime to modules, taking care not to break stuff. Not completed; so far so good. Delivering a non-trivial Cloudflare Worker demo. We already have a trivial one working. It's trivial because it only does synchronous request -> response computation; more \"real-world\" ones will need to invoke asynchronous JavaScript computation (e.g. using Fetch API) Dealing with JavaScript asynchronous computation is not quite tolerable yet; we need to litter the code with makeHaskellCallback* , at least one such call for a JavaScript await . We currently have two potential approaches of improving user experience with async js code: Implement some CPS-based EDSL to automatically deal with callback marshaling. Implement a simple IO manager in the runtime which is capable of suspending Haskell threads when calling async js code and resuming them upon resolving/rejecting. The second one sounds much more decent, but has a high difficulty level. We'll start from the first one. Rough plans for next week: Finish the work on modularizing the runtime, document new behavior of JavaScript generation, then merge to master . Deliver a more decent Cloudflare worker demo which calls some async js code.","title":"Status reports"},{"location":"reports/#status-reports","text":"This page maintains a list of weekly status reports for the project.","title":"Status reports"},{"location":"reports/#2019-02-04","text":"Covers last week. Ongoing work: Finished the preliminary implementation of GC. To increase reliability and catch regressions, after each GC pass, the recycled space is zeroed. If the tospace still contains pointers to recycled space (which is definitely a bug), the program is likely to crash early. This has helped us to identify & fix a few bugs in the GC implementation. Right now there is only one regression left: the todomvc example crashes after initial loading completes. The crash goes away if we don't zero recycled space, but it's not a good idea to just turn that off and pretend there's no bug! Remaining work for GC: Fix the todomvc regression. Given GC is such a critical component in the runtime, it's probably also good timing to integrate some more unit tests from the GHC test suite. This also needs some improvement in our debugging infrastructure: our memory traps (wasm read/write barriers) is currently unaware of recycled/live space, and now we should make it cooperate with the allocator to catch invalid access to recycled space earlier. Known drawbacks of current GC implementation once it's fully fixed & merged: No generational GC yet, so high GC overhead if a large volume of long-lived data is retained through program execution. Heap fragmentation is more severe when allocating a lot of small pinned objects. Weak# support is expected to split into two different stages and will land after initial GC merge: Support for running \"C finalizers\" added by the addCFinalizerToWeak# primop. Here, the \"C finalizers\" are really just JavaScript functions, and the \"function pointers\" are JavaScript references. Support for running arbitrary IO action as finalizers. This task requires support for Haskell multi-threading, and given multi-threading is not a scheduled goal of 2019 Q1, this will come later. Haskell closures exported to JavaScript using makeHaskellCallback* cannot be automatically recycled when they aren't used anymore. This is due to JavaScript's lacking of finalizers; users will need to call freeHaskellCallback* by hand to prevent leaking on the Haskell side. We'll yield to Cabal support & TH/GHCi/Plugins support after the first version of GC is delivered. There's definitely room for improvement later (e.g. reduce heap fragmentation, different GC algorithms for different workloads, more detailed GC statistics, etc), but those will be managed by separate tickets.","title":"2019-02-04"},{"location":"reports/#2019-01-28","text":"Covers last week. Ongoing work: More work to improve the sanity checker and get GC near completion: The sanity checker spotted a fatal situation where previously unreachable static closures become reachable again. More experiments in this direction invalidated a previous conjecture that no special treatments for static closure is required as long as they have valid block descriptors and can be moved just like dynamic ones. The solution to the problem above is not hard: when scanning an info table, we also follow the SRT if it's present, and we still need to identify static/dynamic closures and prevent moving static ones. This is implemented in the sanity checker. The sanity checker is no longer backed by explicit recursion. When scanning a long chain of closures, we won't run out of JavaScript stack space. Adjusting the codegen & standard libraries to cope with upcoming GC: The makeHaskellCallback* interfaces now properly allocate a stable pointer for the exported Haskell closure. This is to ensure that they remain valid when later called from JavaScript, even after GC runs. The function closures of foreign export javascript clauses are recognized and become GC roots for similar reasons. Asterius.Types is moved from ghc-prim to base , so the JSVal type can be backed by StablePtr . The GC will use a tag bit to identify regular stable pointers and JavaScript references, and automatically free unused references. Integer is promoted to a standalone datatype, so the GC can scan reachable Integer s and free unreachable ones which point to BigInt s. Remaining work for GC: Implement evac/scav functionality. Implement support for Weak# s based on the constraint that no Haskell execution is required when firing a finalizer.","title":"2019-01-28"},{"location":"reports/#2019-01-21","text":"Covers last week. Ongoing work: Bugfixes & partially done GC work of later stages (recycling Haskell heap space & JavaScript references): Unified treatment of regular StablePtr# s and JSVal in the runtime. They are identified by a tag bit, and GC will be able to recognize live JSVal s when scanning the Haskell heap. Added the SPT as sanity check/garbage collection roots. Fixed a sanity check bug related to AP/PAP heap objects. This could be triggered when checking the SPT after passing a closure built by chained rts_apply calls to rts_evalStableIO . Reimplemented the linker layout code. We now put non-closures & closures to separate regions, and the regions are statically allocated block groups which is handled by the sm uniformly like dynamically allocated groups. This enables us to treat static closures as if they're dynamic ones without any special hack. Simplified the block allocator. We no longer manage block at 4K granularity; now we only manage 1M sized ones. Pros & cons: Much fewer blocks needed to manage, so simpler/faster runtime code. Larger nurseries mean the Haskell mutator code signals HeapOverflow much less frequently. Should reduce amortized GC cost. The main drawback is increated heap fragmentation when it comes to allocating lots of small pinned objects. This is not yet a primary concern, and can be addressed later by a hybrid GC which switches to non-moving mark-sweep algorithm for block groups with pinned objects. Added functionality to free block groups, so they can later be reused without growing the linear memory. Their payloads can be zeroed to eliminate a potential attack surface (or for better reproduction of bugs in case something goes wrong) Moved allocate* to the JavaScript runtime and properly implemented allocatePinned . Previously it was simply an alias of allocate since we didn't move anything around. Planned work for next week: Wrap up all GC work and get a fully functional GC up & running. This was originally planned to finish by end of last week, but fell behind schedule due to the hidden workload described above. Required work: Implement evac/scav functionalities in the runtime. Remove the now obsolete symbol table exporting mechanism, and any closure required to survive all GC scans need to be explicitly present in the SPT upon startup. Remove the terrible hacks of directly coercing between GC pointers of boxed types and regular Addr# s when crossing the FFI boundary. Now we must properly pass StablePtr# s. Breaking refactorings in the current boot libs: The JSVal family of types need to be moved from ghc-prim to base (or a separate package depending on base ), since it needs to be a newtype wrapper of StablePtr which is defined in base . The Integer type gets promoted to a standalone datatype. We still use tagging to identify small Integer s and BigInt s which is managed by SPT just like other JSVal s.","title":"2019-01-21"},{"location":"reports/#2019-01-13","text":"Covers the last week. The week before was new year vacation; happy new year everyone! Completed & ongoing work: Completed the \"modularized runtime\" refactorings. (#50) Drafted three feature roadmaps: Implement proper garbage collection (#52) Implement Cabal support (#53) Implement support for Template Haskell/GHCi/Plugins (#54) The above proposals are scheduled to be completed on 2019 Q1. Began working on GC, and finished the first stage: accurate heap objects traversal. Identify different types of data sections in object files (regular bytes/info tables/closures). The info table addresses are emitted into generated JavaScript to allow an accurate info table sanity check. Implemented runtime utils for directly manipulating the linear memory with tagged addresses. Implemented the sanity check which traverses the whole heap and visits every live object. All existing unit tests pass this check. Planned work for next week: Finish the second stage of GC support: evacuate/scavenge. See #52 for details. After this is finished, GC will be operational. Support for handling JSVal and Weak# is scheduled in later stages. Originally scheduled but lowered priority: Improving the Cloudflare worker demo. We're prioritizing more pressing issues like GC over specific use cases right now. Special thanks to Moritz Angermann (@angerman) for contributing a patch (#55) for fixing ar problem on macOS, and helping to improve macOS & cabal support, discovering a GHC bug related to tables-next-to-code (#16174).","title":"2019-01-13"},{"location":"reports/#2018-12-28","text":"Covers the last two weeks. Completed work: Significant refactorings in the runtime. Pruned ~500 loc weed code in Asterius.Builtins without breaking tests. Enhanced the scheduler. Previously, when entering a Haskell thread, we evaluated to completion and checked the return code; if something goes wrong, we would just throw an error. Now, the scheduler is capable of handling certain scenarios like heap overflow and resuming Haskell execution. Enhanced the storage manager. Previously, the block allocator always triggered a grow_memory opcode when requesting blocks, making a lot of Array# / ByteArray# related primops rather in-efficient. Also, we allocated a huge heap (defaults to 1G) upon startup and pretended it won't run out. Now, the block allocator grows the linear memory efficiently. And the initial heap is small (4K for both the nursery and the object pool); an overflow condition automatically extends it. Implemented the \"persistent vault\" feature. Every asterius instance has a KV store called a \"vault\" which can be accessed in both Haskell/JavaScript. It can be used to transfer state across instances, so when an instance throws errors we can't handle, we can restart a new one without losing context. This is a part of the work for Cloudflare Worker showcase. Delivered a working TodoMVC example and issued a blog post. Other notable bugfixes/improvements: Fixed the dirty_MUT_VAR write barrier for MutVar# s. All non-atomic MutVar# / IORef / STRef operations now work. This is a part of the work for TodoMVC showcase. We implemented UTF8/UTF16-LE/UTF32-LE/Latin-1 encoding/decoding in the runtime. This is a part of the work for text support. The makeHaskellCallback functions are slightly more efficient by avoiding the overhead of allocating StablePtr s. On-going work not completed yet: Modularizing the runtime. Previously, the runtime is a single monolithic JavaScript script which is pasted into the output script. We'd like to split it to modules, and allow users to supply their own module to override the default behavior (evaluating Main.main once). Rationales: For users, it's much more convenient to implement custom logic via a proper module file. Especially in the Cloudflare Worker case, where we need: Fully synchronous initialization Capturing errors/rebooting a new instance It's now possible to write tests for individual pieces of the runtime. This is critical to improve the runtime's reliability. There were some pasted parts in the monolithic runtime; now we can properly reuse code. It's also convenient to inject link-time information into the runtime. We've introduced parcel into our toolchain to implement a \"bundling\" functionality: at link-time, re-generating a standalone .js file containing all the runtime modules. This is already implemented. We're gradually splitting the monolithic runtime to modules, taking care not to break stuff. Not completed; so far so good. Delivering a non-trivial Cloudflare Worker demo. We already have a trivial one working. It's trivial because it only does synchronous request -> response computation; more \"real-world\" ones will need to invoke asynchronous JavaScript computation (e.g. using Fetch API) Dealing with JavaScript asynchronous computation is not quite tolerable yet; we need to litter the code with makeHaskellCallback* , at least one such call for a JavaScript await . We currently have two potential approaches of improving user experience with async js code: Implement some CPS-based EDSL to automatically deal with callback marshaling. Implement a simple IO manager in the runtime which is capable of suspending Haskell threads when calling async js code and resuming them upon resolving/rejecting. The second one sounds much more decent, but has a high difficulty level. We'll start from the first one. Rough plans for next week: Finish the work on modularizing the runtime, document new behavior of JavaScript generation, then merge to master . Deliver a more decent Cloudflare worker demo which calls some async js code.","title":"2018-12-28"},{"location":"rts-api/","text":"Invoking RTS API in JavaScript For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . rts_evalStableIO evaluates the result of StablePtr (IO a) to WHNF, then return the result as StablePtr a . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"rts-api/#invoking-rts-api-in-javascript","text":"For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . rts_evalStableIO evaluates the result of StablePtr (IO a) to WHNF, then return the result as StablePtr a . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"vault/","text":"The \"Vault\" Asterius provides a \"persistent vault\" feature, which provides a KV store per asterius instance, and the store can be accessed in both Haskell and JavaScript. The vault enables compiled Haskell code to reuse some state, even if the whole asterius instance is wiped and restarted. See GitHub issue 48 for further explanation. The Haskell API is in Asterius.Vault in base : vaultInsert :: JSArrayBuffer -> JSVal -> IO () vaultLookup :: JSArrayBuffer -> IO (Maybe JSVal) vaultDelete :: JSArrayBuffer -> IO () The key of a vault is a JSArrayBuffer , typically converted from a ByteString . The value can be JSVal , which can be coerce ed from any JS* type. In JavaScript, assuming i is the asterius instance, then i.vault is the instance vault. i.vault defaults to empty, and can be passed around, modified and assigned. The i.vault value is a Map object which uses immutable String s converted from ArrayBuffer s as keys. It's only safe to manipulate keys in JavaScript when you're sure the strings only encode Latin-1 characters.","title":"The Vault"},{"location":"vault/#the-vault","text":"Asterius provides a \"persistent vault\" feature, which provides a KV store per asterius instance, and the store can be accessed in both Haskell and JavaScript. The vault enables compiled Haskell code to reuse some state, even if the whole asterius instance is wiped and restarted. See GitHub issue 48 for further explanation. The Haskell API is in Asterius.Vault in base : vaultInsert :: JSArrayBuffer -> JSVal -> IO () vaultLookup :: JSArrayBuffer -> IO (Maybe JSVal) vaultDelete :: JSArrayBuffer -> IO () The key of a vault is a JSArrayBuffer , typically converted from a ByteString . The value can be JSVal , which can be coerce ed from any JS* type. In JavaScript, assuming i is the asterius instance, then i.vault is the instance vault. i.vault defaults to empty, and can be passed around, modified and assigned. The i.vault value is a Map object which uses immutable String s converted from ArrayBuffer s as keys. It's only safe to manipulate keys in JavaScript when you're sure the strings only encode Latin-1 characters.","title":"The \"Vault\""},{"location":"wasm-in-hs/","text":"Writing WebAssembly code in Haskell In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"wasm-in-hs/#writing-webassembly-code-in-haskell","text":"In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"webassembly/","text":"WebAssembly as a Haskell compilation target There are a few issues to address when compiling Cmm to WebAssembly. Implementing Haskell Stack/Heap The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise. Implementing STG machine registers The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable . Handling control flow WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away. Handling relocations When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity. The word size story Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 . Pages and addresses The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#webassembly-as-a-haskell-compilation-target","text":"There are a few issues to address when compiling Cmm to WebAssembly.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#implementing-haskell-stackheap","text":"The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.","title":"Implementing Haskell Stack/Heap"},{"location":"webassembly/#implementing-stg-machine-registers","text":"The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable .","title":"Implementing STG machine registers"},{"location":"webassembly/#handling-control-flow","text":"WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.","title":"Handling control flow"},{"location":"webassembly/#handling-relocations","text":"When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity.","title":"Handling relocations"},{"location":"webassembly/#the-word-size-story","text":"Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 .","title":"The word size story"},{"location":"webassembly/#pages-and-addresses","text":"The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"Pages and addresses"}]}